<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ONNX Chatbot with Tokenizer</title>
  <style>
    body { font-family: sans-serif; padding: 20px; }
    #chat { border: 1px solid #ccc; padding: 10px; height: 300px; overflow-y: auto; }
    input { width: 80%; padding: 5px; }
    button { padding: 5px 10px; }
  </style>
</head>
<body>
  <h2>ONNX Chatbot</h2>
  <div id="chat"></div>
  <input id="userInput" placeholder="Say something..." />
  <button onclick="sendMessage()">Send</button>

  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@huggingface/tokenizers@0.11.1/dist/tokenizers.min.js"></script>

  <script>
    let session;
    let tokenizer;

    async function init() {
      // Load ONNX model
      session = await ort.InferenceSession.create('./model/model.onnx');
      log("ðŸ¤– Model loaded");

      // Load tokenizer from JSON
      const response = await fetch('./model/tokenizer.json');
      const tokenizerJSON = await response.json();
      tokenizer = await Tokenizers.fromJSON(tokenizerJSON);
      log("ðŸ§© Tokenizer loaded");
    }

    function log(text, sender = 'ðŸ¤–') {
      const chat = document.getElementById('chat');
      const msg = document.createElement('div');
      msg.textContent = `${sender} ${text}`;
      chat.appendChild(msg);
      chat.scrollTop = chat.scrollHeight;
    }

    async function sendMessage() {
      const inputBox = document.getElementById('userInput');
      const userText = inputBox.value.trim();
      if (!userText) return;

      log(userText, "ðŸ§‘");
      inputBox.value = "";

      // Tokenize input text
      const encoded = tokenizer.encode(userText);
      const inputIds = encoded.ids;

      // Create tensor (int64 or int32 depending on model)
      const inputTensor = new ort.Tensor('int64', BigInt64Array.from(inputIds.map(BigInt)), [1, inputIds.length]);

      const feeds = {};
      feeds[session.inputNames[0]] = inputTensor;

      try {
        const results = await session.run(feeds);

        // Assuming model output is token ids
        const outputName = session.outputNames[0];
        const outputIds = results[outputName].data;

        // Decode output tokens to string
        // If output tensor is Int64Array, convert to numbers first
        const decodedIds = Array.from(outputIds).map(id => Number(id));
        const decodedText = tokenizer.decode(decodedIds, { skipSpecialTokens: true });

        log(decodedText);
      } catch (e) {
        log("Error: " + e.message);
        console.error(e);
      }
    }

    init();
  </script>
</body>
</html>